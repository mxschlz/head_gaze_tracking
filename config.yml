#-----------------------------------------------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------------------------------------------

# Parameters Documentation

## User-Specific Measurements
# USER_FACE_WIDTH: The horizontal distance between the outer edges of the user's cheekbones in millimeters.
# This measurement is used to scale the 3D model points for head pose estimation.
# Measure your face width and adjust the value accordingly.
USER_FACE_WIDTH: 150  # [mm]
USE_ATTENTION_MESH: True
## Camera Parameters (not currently used in calculations)
# NOSE_TO_CAMERA_DISTANCE: The distance from the tip of the nose to the camera lens in millimeters.
# Intended for future use where accurate physical distance measurements may be necessary.
NOSE_TO_CAMERA_DISTANCE: 600  # [mm]
## Configuration Parameters
# PRINT_DATA: Enable or disable the printing of data to the console for debugging.
PRINT_DATA: True
FLIP_VIDEO: False  # this needs to be FALSE because only then are landmark indices correct
# SHOW_ALL_FEATURES: If True, display all facial landmarks on the video feed.
SHOW_ALL_FEATURES: True
# LOG_DATA: Enable or disable logging of data to a CSV file.
LOG_DATA: True
# LOG_ALL_FEATURES: If True, log all facial landmarks to the CSV file.
LOG_ALL_FEATURES: False
# ENABLE_HEAD_POSE: Enable the head position and orientation estimator.
ENABLE_HEAD_POSE: True
# Use socket module to send data to other devices in real time.
USE_SOCKET: False
## Server Configuration
# SERVER_IP: IP address of the server for sending data via UDP (default is localhost).
SERVER_IP: "127.0.0.1"
# SERVER_PORT: Port number for the server to listen on.
SERVER_PORT: 7070
## Blink Detection Parameters
# SHOW_ON_SCREEN_DATA: If True, display blink count and head pose angles on the video feed.
SHOW_ON_SCREEN_DATA: True
# BLINK_THRESHOLD: Eye aspect ratio threshold below which a blink is registered.
BLINK_THRESHOLD: 0.51
# EYE_AR_CONSEC_FRAMES: Number of consecutive frames below the threshold required to confirm a blink.
EYE_AR_CONSEC_FRAMES: 1
## MediaPipe Model Confidence Parameters
# These thresholds determine how confidently the model must detect or track to consider the results valid.
MIN_DETECTION_CONFIDENCE: 0.01  # I think these are the original values
MIN_TRACKING_CONFIDENCE: 0.01
## Angle Normalization Parameters
# MOVING_AVERAGE_WINDOW: The number of frames over which to calculate the moving average for smoothing angles.
MOVING_AVERAGE_WINDOW: 10
## Head Pose Estimation Landmark Indices
# These indices correspond to the specific facial landmarks used for head pose estimation.
LEFT_EYE_IRIS: [474, 475, 476, 477]
RIGHT_EYE_IRIS: [469, 470, 471, 472]
RIGHT_EYE_POINTS: [33, 160, 159, 158, 133, 153, 145, 144]
LEFT_EYE_POINTS: [362, 385, 386, 387, 263, 373, 374, 380]
RIGHT_EYE_OUTER_CORNER: 33
RIGHT_EYE_INNER_CORNER: 133
LEFT_EYE_INNER_CORNER: 362
LEFT_EYE_OUTER_CORNER: 263
NOSE_TIP_INDEX: 4
CHIN_INDEX: 152
RIGHT_MOUTH_CORNER: 61
LEFT_MOUTH_CORNER: 291
# Face Selected points indices for Head Pose Estimation
_indices_pose: [1, 33, 61, 199, 263, 291]
MAX_NUM_FACES: 1
TIMESTAMP_FORMAT: '%Y%m%d%H%M%S%f'
# Rotate the video frame if needed
ROTATE: 180
# --- Video-based Trial Detection Parameters ---
ENABLE_VIDEO_TRIAL_DETECTION: True  # Main switch for this feature
ENABLE_EYE_GAZE_CHECK: True  # This switches from the old head-pose-only approach to a new combined method of head pose and gaze
AUTO_CALIBRATE_ON_START: True  # auto-calibrate head position on start
ENABLE_HEAD_POSE_FILTER_FOR_EYE_GAZE: True  # if True, also uses head position besides eye gaze for stimulus-gaze categorization
# Defines the ROI for stimulus detection on the VIDEO FRAME (after any flip/rotate)
# [x_top_left, y_top_left, width, height]
# YOU MUST DETERMINE THESE VALUES FOR YOUR VIDEO SETUP
STIMULUS_ROI_COORDS: [820, 630, 300, 300] # Example: top-left 100x100 px square

# Dynamic Brightness Baseline (more robust)
ROI_BRIGHTNESS_BASELINE_FRAMES: 50   # Nr. of initial non-trial frames to establish baseline brightness
ROI_BRIGHTNESS_THRESHOLD_FACTOR: 1.5 # Stimulus onset if ROI brightness > baseline * factor
# OR, if you prefer an absolute threshold (less robust):
# ROI_ABSOLUTE_BRIGHTNESS_THRESHOLD: 180 # (0-255) - comment out if using a factor

STIMULUS_DURATION_MS: 800             # How long stimulus is considered "on" after detection
POST_STIMULUS_TRIAL_DURATION_MS: 0  # How long a trial continues after stimulus duration
MIN_INTER_TRIAL_INTERVAL_MS: 1000      # Min time from one trial's end to the next potential start

# --- Gaze on Stimulus Parameters (these might already exist or be similar) ---
# Define where the baby should look (in terms of calibrated head pose)
STIMULUS_PITCH_RANGE: [-10, 10]  # [min_pitch, max_pitch] degrees from calibrated neutral
STIMULUS_YAW_RANGE: [-10, 10]    # [min_yaw, max_yaw] degrees from calibrated neutral

STIMULUS_LEFT_IRIS_DX_RANGE: [-20, -10]  # pixel values from neutral
STIMULUS_LEFT_IRIS_DY_RANGE: [0, 5]  # pixel values from neutral
STIMULUS_RIGHT_IRIS_DX_RANGE: [10, 20]  # pixel values from neutral
STIMULUS_RIGHT_IRIS_DY_RANGE: [-5, 0]  # pixel values from neutral

# Head Pose Auto-Calibration Settings
HEAD_POSE_AUTO_CALIBRATION_ENABLED: True  # Master switch for this feature
HEAD_POSE_AUTO_CALIB_DURATION_FRAMES: 150 # How many frames to attempt calibration (e.g., 5s @ 30fps)
HEAD_POSE_AUTO_CALIB_MIN_SAMPLES: 30      # Min number of "good" samples needed within the duration
# Eye gaze dx/dy ranges (pixels, relative to eye corner) to consider eyes "looking forward" for calibration
HEAD_POSE_AUTO_CALIB_EYE_DX_RANGE: [-20, 20] # Allowable horizontal deviation of iris center from eye corner
HEAD_POSE_AUTO_CALIB_EYE_DY_RANGE: [-20, 20] # Allowable vertical deviation of iris center from eye corner

# Head Pose Filter Settings
HEAD_POSE_FILTER_PITCH_RANGE: [-15, 15]
HEAD_POSE_FILTER_YAW_RANGE: [-15, 15]

# Min % of STIMULUS_DURATION_MS gaze must be on stimulus area for trial to be '1'
LOOK_TO_STIMULUS_THRESHOLD_PERCENT: 60

# --- Output ---
OUTPUT_TRIAL_SUMMARY_FILENAME_PREFIX: "baby_gaze_trial_summary"
OUTPUT_VIDEO_FOURCC: "XVID"  # Examples: "mp4v" (for .mp4), "XVID" (for .avi), "MJPG"

SPLIT_VIDEO_AT_MS: 655000  # cut video here (in ms)

# Suffixes to append to output filenames for each part if splitting
OUTPUT_FILENAME_SUFFIX_PART1: "_part1"
OUTPUT_FILENAME_SUFFIX_PART2: "_part2"
